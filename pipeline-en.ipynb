{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dfa678b",
   "metadata": {},
   "source": [
    "## Data Science Project Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4827947",
   "metadata": {},
   "source": [
    "### Uploading a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732267b5",
   "metadata": {},
   "source": [
    "### EDA + Feature Engineering:\n",
    "- Observe missing values, data types. Also, observe the dataset, make up hypothesis, make graphs based on assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084a97d",
   "metadata": {},
   "source": [
    "#### How to fill in the missing values?\n",
    "- Replace with 0 in case of int, float dtypes\n",
    "- With average values (average, median, mode)\n",
    "- Remove NaNs (if they are not too much)\n",
    "- Replace with None in case of categorical variables\n",
    "\n",
    "#### How to deal with outliers?\n",
    "- Remove them (if they are not too much)\n",
    "- Preprocess them (example https://youtu.be/Vgm2ddpdnxA)\n",
    "- Take logarithm\n",
    "- Apply statistical methods\n",
    "- Use clusterization (methods based on density) \\\n",
    "\n",
    "P.S: Outliers can be detected on EDA stage, using boxplot, displot, statistics, clusterization methods\n",
    "\n",
    "#### Before choosing a model:\n",
    "- Observe the dependence between the features and target - this will help to choose type of model: regression/classification\n",
    "- Check the distribution of the target variable, if it is far from normal, where normality can be checked using Shapiro-Wilk test, then we should take logarithm\n",
    "- If the type is classification, we should look whether there is disbalance, and if yes, we can use built-in methods such as, class_weight=\"balanced\", or SMOTE/oversampling/undersampling\n",
    "- If there are categorical variables, we should encode them using One-Hot encoding, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2725d8c6",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4f737b",
   "metadata": {},
   "source": [
    "#### Normalization:\n",
    "- When using linear models\n",
    "- When using metric algorithms, such as KNN\n",
    "- When using Neural Networks\n",
    "\n",
    "#### Before going further with specific model:\n",
    "- If there are many features (~ 500), then we should do feature selection based on importance of the feature (https://habr.com/ru/company/ods/blog/325422/)\n",
    "- If the dataset is small, simple algorithm should be used (no Boostings)\n",
    "- If the dependence is non-trivial, then use tree-based models, + if the dataset is huge, then boosting, ansambles, stackings\n",
    "\n",
    "#### Choosing a metric:\n",
    "- For regression problem: MSE, RMSE, etc.\n",
    "- For classification problem: accuracy (if no disbalance), f1, roc_auc, precision, recall, logloss. etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a81e50",
   "metadata": {},
   "source": [
    "### Choosing optimal parameters, modeling + picking out important parameters\n",
    "- For seeking optimal parameters: GridSearch - iterates over all indicated params\n",
    "- Optuna and other methods. Works faster, usually more efficient\n",
    "- Use cross-validation in order to avoid overfitting. For disbalanced dataset, apply methods with stratification, e.g. StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a580b01",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "- permutation_importance - gives more detailed view with the most important features\n",
    "- SHAP - gives information about how each of the features influences on target variable(s)\n",
    "- make conclusions about whether your initial hypothesis worked or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ae1b4",
   "metadata": {},
   "source": [
    "                                                                                                        @meeka"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
